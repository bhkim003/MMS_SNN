{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_assign(seed):\n",
    "    random.seed(seed)                          # Python random 시드 고정\n",
    "    np.random.seed(seed)                       # NumPy 시드 고정\n",
    "    torch.manual_seed(seed)                    # PyTorch CPU 시드 고정\n",
    "    torch.cuda.manual_seed(seed)               # PyTorch GPU 시드 고정\n",
    "    torch.cuda.manual_seed_all(seed)           # PyTorch 멀티 GPU 시드 고정\n",
    "    torch.backends.cudnn.deterministic = True  # 연산의 결정론적 동작 보장\n",
    "    # torch.backends.cudnn.benchmark = False     # 성능 최적화 비활성화 (결정론적 보장)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNN(torch.nn.Module):\n",
    "    def __init__(self, v_decay, v_threshold, v_reset_mode, sg_width, surrogate, CLASS_NUM, in_channels, IMAGE_SIZE, time_step):\n",
    "        super(SNN, self).__init__()\n",
    "        self.TIME = time_step\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=in_channels, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        IMAGE_SIZE = (IMAGE_SIZE + 2 - 3 // 1) + 1\n",
    "\n",
    "        self.lif1 = modules.neuron.LIF_layer(v_decay, v_threshold, v_reset_mode, sg_width, surrogate)\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(32 * IMAGE_SIZE * IMAGE_SIZE, CLASS_NUM)\n",
    "\n",
    "        self.lif2 = modules.neuron.LIF_layer(v_decay, v_threshold, v_reset_mode, sg_width, surrogate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # SHAPE : [Batch, Time_step, Channel, H, W]\n",
    "\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "        # SHAPE : [Time_step, Batch, Channel, H, W]\n",
    "\n",
    "        T, B, *spatial_dims = x.shape\n",
    "        x = x.reshape(T * B, *spatial_dims)\n",
    "        # SHAPE : [Time_step * Batch, Channel, H, W]\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        # SHAPE : [Time_step * Batch, Channel, H, W]\n",
    "\n",
    "        TB, *spatial_dims = x.shape\n",
    "        x = x.reshape(self.TIME , TB // self.TIME, *spatial_dims)\n",
    "        # SHAPE : [Time_step, Batch, Channel, H, W]\n",
    "\n",
    "        x = self.lif1(x)\n",
    "        # SHAPE : [Time_step, Batch, Channel, H, W]\n",
    "        \n",
    "        T, B, *spatial_dims = x.shape\n",
    "        x = x.reshape(T * B, *spatial_dims)\n",
    "        # SHAPE : [Time_step * Batch, Channel, H, W]\n",
    "\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        # SHAPE : [Time_step * Batch, CLASS_NUM]\n",
    "\n",
    "        TB, *spatial_dims = x.shape\n",
    "        x = x.reshape(self.TIME , TB // self.TIME, *spatial_dims)\n",
    "        # SHAPE : [Time_step, Batch, CLASS_NUM]\n",
    "\n",
    "        x = self.lif2(x)\n",
    "        # SHAPE : [Time_step, Batch, CLASS_NUM]\n",
    "\n",
    "        x = x.sum(dim=0)\n",
    "        # SHAPE : [Batch, CLASS_NUM]\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snn_system(seed,\n",
    "                which_data,\n",
    "                batch_size,\n",
    "                data_path,\n",
    "                learning_rate,\n",
    "                time_step,\n",
    "                v_decay,\n",
    "                v_threshold,\n",
    "                v_reset_mode,\n",
    "                sg_width,\n",
    "                surrogate,\n",
    "                max_epoch,\n",
    "                gpu):\n",
    "    seed_assign(seed)\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_loader, test_loader, CLASS_NUM, in_channels, IMAGE_SIZE = modules.data_loader.data_loader(which_data, data_path, batch_size)\n",
    "    net = SNN(v_decay=v_decay, v_threshold=v_threshold, v_reset_mode=v_reset_mode, sg_width=sg_width, surrogate=surrogate, CLASS_NUM=CLASS_NUM, in_channels=in_channels, IMAGE_SIZE=IMAGE_SIZE, time_step=time_step)\n",
    "    net = net.to(device)\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    # optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "\n",
    "    for epoch in range(max_epoch):\n",
    "        print(f'Epoch-{epoch}')\n",
    "        net.train()\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        train_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            images = images.unsqueeze(1).repeat(1, time_step, 1, 1, 1)  # repeat 코딩. rate코딩 등을 실험해봐도 좋다. # (batch, time_step, C, H, W)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Training accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        training_accuracy = 100 * correct_train / total_train\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        print(f'Training_loss: {avg_train_loss:.4f}, Training_accuracy: {training_accuracy:.2f} %')\n",
    "\n",
    "        # Validation\n",
    "        net.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                images = images.unsqueeze(1).repeat(1, time_step, 1, 1, 1)  # repeat 코딩. rate코딩 등 실험해봐도 좋다. # (batch, time_step, C, H, W)\n",
    "\n",
    "                outputs = net(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        validation_accuracy = 100 * correct / total\n",
    "        avg_val_loss = val_loss / len(test_loader)\n",
    "        print(f'Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {validation_accuracy:.2f} %')\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-0\n",
      "Training_loss: 4.2778, Training_accuracy: 23.14 %\n",
      "Validation Loss: 3.5227, Validation Accuracy: 29.75 %\n",
      "\n",
      "Epoch-1\n",
      "Training_loss: 1.1334, Training_accuracy: 73.37 %\n",
      "Validation Loss: 0.3618, Validation Accuracy: 87.36 %\n",
      "\n",
      "Epoch-2\n",
      "Training_loss: 0.2866, Training_accuracy: 90.08 %\n",
      "Validation Loss: 0.1287, Validation Accuracy: 96.33 %\n",
      "\n",
      "Epoch-3\n",
      "Training_loss: 0.1039, Training_accuracy: 97.22 %\n",
      "Validation Loss: 0.0979, Validation Accuracy: 97.19 %\n",
      "\n",
      "Epoch-4\n",
      "Training_loss: 0.0791, Training_accuracy: 97.85 %\n",
      "Validation Loss: 0.0988, Validation Accuracy: 97.21 %\n",
      "\n",
      "Epoch-5\n",
      "Training_loss: 0.0580, Training_accuracy: 98.28 %\n",
      "Validation Loss: 0.0925, Validation Accuracy: 97.12 %\n",
      "\n",
      "Epoch-6\n",
      "Training_loss: 0.0480, Training_accuracy: 98.58 %\n",
      "Validation Loss: 0.0950, Validation Accuracy: 97.45 %\n",
      "\n",
      "Epoch-7\n",
      "Training_loss: 0.0436, Training_accuracy: 98.72 %\n",
      "Validation Loss: 0.1216, Validation Accuracy: 96.42 %\n",
      "\n",
      "Epoch-8\n",
      "Training_loss: 0.0366, Training_accuracy: 98.87 %\n",
      "Validation Loss: 0.0956, Validation Accuracy: 97.56 %\n",
      "\n",
      "Epoch-9\n",
      "Training_loss: 0.0291, Training_accuracy: 99.14 %\n",
      "Validation Loss: 0.0841, Validation Accuracy: 97.61 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "which_data = 'MNIST'\n",
    "batch_size = 64\n",
    "data_path = '/data2' # <-- 데이터셋 경로 nfs로 지정하면 안됩니다. 무슨 말인지 잘 모르겠으면 문의해주세요.\n",
    "learning_rate = 0.001\n",
    "time_step = 10\n",
    "v_decay = 0.5\n",
    "v_threshold = 0.5\n",
    "v_reset_mode = 'soft_reset' # 'soft_reset' or 'hard_reset'\n",
    "sg_width = 4.0 # surrogate gradient width\n",
    "surrogate = 'sigmoid' # 'sigmoid' or 'rectangle' or 'rough_rectangle' or 'hard_sigmoid'\n",
    "max_epoch = 10\n",
    "gpu = '0' # 사용할 GPU 번호\n",
    "\n",
    "snn_system(seed=seed,\n",
    "            which_data=which_data,\n",
    "            batch_size=batch_size,\n",
    "            data_path=data_path,\n",
    "            learning_rate=learning_rate,\n",
    "            time_step=time_step,\n",
    "            v_decay=v_decay,\n",
    "            v_threshold=v_threshold,\n",
    "            v_reset_mode=v_reset_mode,\n",
    "            sg_width=sg_width,\n",
    "            surrogate=surrogate,\n",
    "            max_epoch=max_epoch,\n",
    "            gpu=gpu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
